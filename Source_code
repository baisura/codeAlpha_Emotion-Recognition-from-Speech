pip install numpy pandas librosa tensorflow scikit-learn sounddevice matplotlib


import os
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import sounddevice as sd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Flatten
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report


DATASET_PATH = "dataset/"
emotion_labels = {"happy": 0, "angry": 1, "sad": 2, "neutral": 3, "surprise": 4}  # Define emotions


def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=16000)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    return np.mean(mfccs.T, axis=0)


X, y = [], []
for emotion in os.listdir(DATASET_PATH):  
    emotion_folder = os.path.join(DATASET_PATH, emotion)
    if os.path.isdir(emotion_folder):
        for file in os.listdir(emotion_folder):
            file_path = os.path.join(emotion_folder, file)
            features = extract_features(file_path)
            X.append(features)
            y.append(emotion_labels[emotion])

X = np.array(X)
y = np.array(y)


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#
X_train = np.expand_dims(X_train, axis=2)
X_test = np.expand_dims(X_test, axis=2)

model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(40, 1)),
    LSTM(64, return_sequences=True),
    LSTM(64),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(len(emotion_labels), activation='softmax')
])


model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
model.summary()

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))


y_pred = model.predict(X_test)
y_pred_labels = np.argmax(y_pred, axis=1)
print("Accuracy:", accuracy_score(y_test, y_pred_labels))
print("Classification Report:\n", classification_report(y_test, y_pred_labels))

model.save("emotion_recognition_model.h5")


def record_audio(duration=3, sr=16000):
    print("Recording...")
    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')
    sd.wait()
    return audio.flatten()

print("ðŸŽ¤ Speak for 3 seconds to predict emotion...")
audio_data = record_audio()
features = extract_features(audio_data)
features = np.expand_dims(features, axis=(0, 2))
emotion = model.predict(features)
predicted_emotion = list(emotion_labels.keys())[np.argmax(emotion)]
print("Predicted Emotion:", predicted_emotion)
